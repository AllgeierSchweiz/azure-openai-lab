{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————\n",
    "\n",
    "# Name: Azure OpenAI Assistant for Data Transformations (V1)\n",
    "\n",
    "# Purpose:\n",
    "\n",
    "\n",
    "# Company: Allgeier Schweiz AG\n",
    "# Author: Nicolas Rehder (nrehder@allgeier.ch)\n",
    "# Create for: SDSC 2024\n",
    "# Date Created: 22.01.2024\n",
    "# Last Updated: 22.01.2024\n",
    "# Python Version: 3.10.4\n",
    "\n",
    "#General Sources:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/assistants-quickstart?tabs=command-line&pivots=programming-language-studio\n",
    "\n",
    "#Azure Openai Usage:\n",
    "# https://stackoverflow.com/questions/77986927/in-azure-openai-assistants-when-i-upload-a-file-and-save-it-where-is-that-file-s\n",
    "# https://techcommunity.microsoft.com/t5/fasttrack-for-azure/strategies-for-optimizing-high-volume-token-usage-with-azure/ba-p/4007751#:~:text=Understanding%20tokens%20and%20limits%20in,generation%2C%20translation%2C%20or%20summarization.\n",
    "\n",
    "#Additionals:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n",
    "\n",
    "# Download Python packages (run the below command in terminal if packages have not yet been installed)\n",
    "# pip install -r C:\\Python\\sdsc\\requirements.txt\n",
    "\n",
    "#————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from io import StringIO\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required variables from env file.\n",
    "load_dotenv(dotenv_path=Path(\"C:\\\\Python\\\\azure-openai-lab\\\\.venv\\\\.env\")) #Error sometimes due to \\ or \\\\. Try one or the other.\n",
    "\n",
    "# Load Azure OpenAI Key and Endpoint. These values can be found within the Azure OpenAI Service resource in portal.azure.com under Keys and Endpoint\n",
    "azure_oai_key = os.environ['AZURE_OPENAI_KEY']\n",
    "azure_oai_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key = azure_oai_key,  \n",
    "    api_version = \"2024-02-15-preview\",\n",
    "    azure_endpoint = azure_oai_endpoint\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='assistant-c4VW4rS9mCzb2G6kNZs8qBL7', bytes=976, created_at=1713960021, filename='recipe_extraction.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "path_input = r\"C:\\Python\\azure-openai-lab\\data\\recipe_extraction.csv\" #Change path if required\n",
    "\n",
    "# send the csv file to the assistant purpose files\n",
    "response = client.files.create(\n",
    "  file=open(path_input, \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "print(response)\n",
    "file__id = response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = '''\n",
    "You are a senior data analyst who will work with data in an csv file.\n",
    "You have access to a sandboxed environment for writing python code.\n",
    "When the user asks you to perform your actions, you will use the provided csv file.\n",
    "You will perform data cleansing and transformation steps.\n",
    "Execute each of the steps listed below in your ACTIONS section.\n",
    "\n",
    "ACTIONS:\n",
    "\n",
    "1. Read the csv file into a pandas DataFrame by tab separated values.\n",
    "2. Extract the listed values from the column nutrition and change the datatype to numeric.\n",
    "3. Sum the numeric values from the column nutrition and place them in a new column called nutrition_total. Prepare the results as Table_1.\n",
    "4. Prepare Table_1 as an csv file for download by the user. \n",
    "5. Provide a summary paragraph explaining the preparation of the data set.\n",
    "\n",
    "DO NOT:\n",
    "1. Do not return any images. \n",
    "2. Do not return any other file types.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"data analyst assistant\",\n",
    "    instructions = instructions,\n",
    "    tools = [{\"type\": \"code_interpreter\"}],\n",
    "    model = \"gpt-4-1106-preview\", #You must replace this value with the deployment name for your model.\n",
    "    file_ids=[file__id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_HOcI0EA5qHu6IMw9wr5bl2AV', created_at=1713960030, description=None, file_ids=['assistant-c4VW4rS9mCzb2G6kNZs8qBL7'], instructions='\\nYou are a senior data analyst who will work with data in an csv file.\\nYou have access to a sandboxed environment for writing python code.\\nWhen the user asks you to perform your actions, you will use the provided csv file.\\nYou will perform data cleansing and transformation steps.\\nExecute each of the steps listed below in your ACTIONS section.\\n\\nACTIONS:\\n\\n1. Read the csv file into a pandas DataFrame by tab separated values.\\n2. Extract the listed values from the column nutrition and change the datatype to numeric.\\n3. Sum the numeric values from the column nutrition and place them in a new column called nutrition_total. Prepare the results as Table_1.\\n4. Prepare Table_1 as an csv file for download by the user. \\n5. Provide a summary paragraph explaining the preparation of the data set.\\n\\nDO NOT:\\n1. Do not return any images. \\n2. Do not return any other file types.\\n', metadata={}, model='gpt-4-1106-preview', name='data analyst assistant', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])\n"
     ]
    }
   ],
   "source": [
    "# Get the file id\n",
    "fileId = assistant.file_ids[0]\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a user prompt to the thread\n",
    "\n",
    "prompt = \"Please execute your ACTIONS on the data stored in the csv file \" + fileId\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = \"user\",\n",
    "    content = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Assistant\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  #instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in progress...\n",
      "in progress...\n",
      "in progress...\n",
      "in progress...\n",
      "in progress...\n",
      "Assistant: It appears that there is a technical issue preventing me from processing the CSV file through this platform. Unfortunately, this issue is out of my control, and I am unable to read the file or perform the subsequent steps at this time. I recommend trying again later or contacting support if the issue persists. My apologies for the inconvenience.\n",
      "Assistant: It seems the previous environment where pandas was loaded has been reset and pandas is no longer recognized. I will need to import pandas again and then proceed with loading the CSV file. Let's go through this step once more.\n",
      "Assistant: There seems to be a persistent issue preventing me from reading the data. I will attempt one more time to read and process your CSV file. Let's hope it works this time.\n",
      "Assistant: It looks like there was an issue when attempting to read the data. Let me try to read the csv file again and ensure it is processed correctly.\n",
      "User: Please execute your ACTIONS on the data stored in the csv file assistant-c4VW4rS9mCzb2G6kNZs8qBL7\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sec = 30\n",
    "    # Wait for 30 seconds\n",
    "    time.sleep(sec)  \n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    # If run is completed, get messages\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "        # Loop through messages and print content based on role\n",
    "        for msg in messages.data:\n",
    "            role = msg.role\n",
    "            try:\n",
    "                content = msg.content[0].text.value\n",
    "                print(f\"{role.capitalize()}: {content}\")\n",
    "            except AttributeError:\n",
    "                # This will execute if .text does not exist\n",
    "                print(f\"{role.capitalize()}: [Non-text content, possibly an image or other file type]\")\n",
    "        break\n",
    "    elif run.status == \"requires_action\":\n",
    "        # handle function calling and continue with the execution\n",
    "        pass\n",
    "    elif run.status == \"expired\" or run.status==\"failed\" or run.status==\"cancelled\":\n",
    "        # run failed, expired, or was cancelled\n",
    "        break    \n",
    "    else:\n",
    "        print(\"in progress...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = client.beta.threads.messages.list(\n",
    "#             thread_id=thread.id\n",
    "#         )\n",
    "\n",
    "# messages.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read xlsx files from Azure Openai\n",
    "\n",
    "def read_and_save_file(first_file_id, file_name):    \n",
    "    # its binary, so read it and then make it a file like object\n",
    "    file_data = client.files.content(first_file_id)\n",
    "    file_data_bytes = file_data.read()\n",
    "    file_like_object = io.BytesIO(file_data_bytes)\n",
    "    #now read as csv to create df\n",
    "    returned_data = pd.read_csv(file_like_object)\n",
    "    returned_data.to_csv(file_name, index=False)\n",
    "    return returned_data\n",
    "    # file = read_and_save_file(first_file_id, \"analyst_output.csv\")\n",
    "    \n",
    "def files_from_messages(messages, asst_name):\n",
    "    first_thread_message = messages.data[0]  # Accessing the first ThreadMessage\n",
    "    message_ids = first_thread_message.file_ids\n",
    "    print(message_ids)\n",
    "    # Loop through each file ID and save the file with a sequential name\n",
    "    for i, file_id in enumerate(message_ids):\n",
    "        file_name = f\"{asst_name}_output_{i+1}.csv\"  # Generate a sequential file name\n",
    "        read_and_save_file(file_id, file_name)\n",
    "        print(f'saved {file_name}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# extract the file names from the response and retrieve the content\n",
    "asst_name = 'data_analyst_assistant'        \n",
    "files_from_messages(messages, asst_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='assistant-U63rofolXcnMAtc75dizI5Xz', bytes=976, created_at=1713958466, filename='recipe_extraction.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "for i in client.files.list():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up\n",
    "\n",
    "client.beta.assistants.delete(assistant.id)\n",
    "client.beta.threads.delete(thread.id)\n",
    "for i in client.files.list():\n",
    "    client.files.delete(i.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in client.beta.assistants.list():\n",
    "    client.beta.assistants.delete(i.id)\n",
    "for i in client.beta.threads.list():\n",
    "    client.beta.threads.delete(i.id)\n",
    "for i in client.files.list():\n",
    "    client.files.delete(i.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "\n",
    "#     # Load data\n",
    "#     path_input = r\"C:\\Python\\data\\openfoodfacts.xlsx\" #Change path if required\n",
    "\n",
    "#     # send the csv file to the assistant purpose files\n",
    "#     response = client.files.create(\n",
    "#     file=open(path_input, \"rb\"),\n",
    "#     purpose=\"assistants\"\n",
    "#     )\n",
    "\n",
    "#     file__id = response.id\n",
    "\n",
    "#     # Create an assistant\n",
    "#     assistant = client.beta.assistants.create(\n",
    "#         name = \"data analyst assistant \" + str(i),\n",
    "#         instructions = instructions,\n",
    "#         tools = [{\"type\": \"code_interpreter\"}],\n",
    "#         model = \"gpt-4-1106-preview\", #You must replace this value with the deployment name for your model.\n",
    "#         file_ids=[file__id]\n",
    "#     )\n",
    "\n",
    "#     fileId = assistant.file_ids[0]\n",
    "\n",
    "#     thread = client.beta.threads.create()\n",
    "\n",
    "#     prompt = \"Please execute your ACTIONS on the data stored in the xlsx file \" + fileId\n",
    "\n",
    "#     message = client.beta.threads.messages.create(\n",
    "#         thread_id = thread.id,\n",
    "#         role = \"user\",\n",
    "#         content = prompt\n",
    "#     )\n",
    "\n",
    "#     run = client.beta.threads.runs.create(\n",
    "#     thread_id=thread.id,\n",
    "#     assistant_id=assistant.id,\n",
    "#     #instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\n",
    "#     )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
