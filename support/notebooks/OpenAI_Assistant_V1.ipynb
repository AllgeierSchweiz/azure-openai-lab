{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b812b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————\n",
    "\n",
    "# Name: OpenAI Assistant (V1)\n",
    "\n",
    "# Purpose:\n",
    "# This notebook will create a GPT Assistant using OpenAI's API and provide it with the training dataframe returned by the data engineer Assistant and a set of instructions to creating an \"Extra Trees\" Random Forest. Basic outline of instructions for the modeler:\n",
    "\n",
    "# 1. Load the provided dataframe into a pandas df.\n",
    "# 2. Split the data set into training and testing using a 75:25 split.\n",
    "# 3. Train an Extra Trees random forest with 2000 trees.\n",
    "# 4. Use the testing data to measure the model's accuracy, presicion, recall, and generate a confusion matrix.\n",
    "# 5. Return the results in a single csv table. \n",
    "\n",
    "# Company: Allgeier Schweiz AG\n",
    "# Author: Nicolas Rehder (nrehder@allgeier.ch)\n",
    "# Create for: SDSC 2024\n",
    "# Date Created: 22.01.2024\n",
    "# Last Updated: 22.01.2024\n",
    "# Python Version: 3.10.4\n",
    "\n",
    "#General Sources:\n",
    "#https://platform.openai.com/docs/api-reference?lang=python\n",
    "#https://medium.com/ai-advances/complete-process-for-fine-tuning-gpt-3-5-turbo-using-openai-api-db4a50b3de1a\n",
    "\n",
    "#Openai Usage:\n",
    "#https://platform.openai.com/usage\n",
    "\n",
    "#Additionals:\n",
    "# - https://platform.openai.com/docs/models\n",
    "# - https://openai.com/pricing\n",
    "\n",
    "# Download Python packages (run the below command in terminal if packages have not yet been installed)\n",
    "#pip install -r C:\\Python\\openai-lab\\support\\requirements\\requirements.txt\n",
    "\n",
    "#————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78367c55-8ca2-4e2b-b651-05fce7b5c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Functions\n",
    "\n",
    "def read_and_save_file(first_file_id, file_name):    \n",
    "    # its binary, so read it and then make it a file like object\n",
    "    file_data = client.files.content(first_file_id)\n",
    "    file_data_bytes = file_data.read()\n",
    "    file_like_object = io.BytesIO(file_data_bytes)\n",
    "    #now read as csv to create df\n",
    "    returned_data = pd.read_csv(file_like_object)\n",
    "    returned_data.to_csv(file_name, index=False)\n",
    "    return returned_data\n",
    "    # file = read_and_save_file(first_file_id, \"analyst_output.csv\")\n",
    "    \n",
    "def files_from_messages(messages, asst_name):\n",
    "    first_thread_message = messages.data[0]  # Accessing the first ThreadMessage\n",
    "    message_ids = first_thread_message.file_ids\n",
    "    print(message_ids)\n",
    "    # Loop through each file ID and save the file with a sequential name\n",
    "    for i, file_id in enumerate(message_ids):\n",
    "        file_name = f\"{asst_name}_output_{i+1}.csv\"  # Generate a sequential file name\n",
    "        read_and_save_file(file_id, file_name)\n",
    "        print(f'saved {file_name}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830eab53-b204-4d22-a715-372f2799f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set key and assistant ID\n",
    "OPENAI_API_KEY = 'your_API_key'\n",
    "\n",
    "# Instantiate the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and check the file for the engineer\n",
    "asst_file = 'tumor.csv'\n",
    "df = pd.read_csv(asst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bde8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the assistant and give it the CSV file\n",
    "\n",
    "mls = '''\n",
    "You are a data engineer who will work with data in a csv file in your files. \n",
    "When the user asks you to perform your actions, use the csv file to read the data into a pandas dataframe.\n",
    "The data set is to be used for a classification model.\n",
    "Execute each of the steps listed below in your ACTIONS section. The user will identify the target variable. \n",
    "\n",
    "ACTIONS:\n",
    "\n",
    "1. Read the file data into a pandas DataFrame. \n",
    "2. Summarize each feature and the target variable in the data set and prepare the results as Table_1.\n",
    "3. Check for missing values and impute the column mean for any missing values.\n",
    "4. Create a two new feature interaction columns for each unique pair of variables, using multiplication for one interaction column and dividion for the other.\n",
    "5. Run a logistic regression to predict the target variable with LASSO to select features. Use a lambda values of 1. \n",
    "6. Prepare the Lasso coefficient values as Table_2.\n",
    "7. Prepare a final data set that only contains features with non-zero LASSO coefficients and the target variable as Table_3\n",
    "8. Provide a summary paragraph explaining the preparation of the data set.\n",
    "9. Prepare Table_1, Table_2, and Table_3 as csv files for download by the user. \n",
    "\n",
    "DO NOT:\n",
    "1. Do not return any images. \n",
    "'''\n",
    "\n",
    "# send the csv file to the assistant purpose files\n",
    "response = client.files.create(\n",
    "  file=open(asst_file, \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "print(response)\n",
    "file__id = response.id\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=mls,\n",
    "    name=\"engine_1\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4-1106-preview\", # gpt-4\n",
    "    file_ids=[file__id]\n",
    ")\n",
    "\n",
    "# get the file id\n",
    "fileId = my_assistant.file_ids[0]\n",
    "print(my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the request to the assistant\n",
    "\n",
    "message_string = \"Please execute your ACTIONS on the data stored in the csv file \" + fileId + \" . The Target variable is Class\"\n",
    "print(message_string)\n",
    "\n",
    "# Step 2: Create a Thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Step 3: Add a Message to a Thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content= message_string\n",
    ")\n",
    "\n",
    "# Step 4: Run the Assistant\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=my_assistant.id\n",
    "    #instructions=\"Overwrite hard-coded instructions here\"\n",
    ")\n",
    "\n",
    "print(run.model_dump_json(indent=4))\n",
    "\n",
    "while True:\n",
    "    sec = 60\n",
    "    # Wait for 5 seconds\n",
    "    time.sleep(sec)  \n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(f'{sec} seconds later...')\n",
    "    # If run is completed, get messages\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "        # Loop through messages and print content based on role\n",
    "        for msg in messages.data:\n",
    "            role = msg.role\n",
    "            try:\n",
    "                content = msg.content[0].text.value\n",
    "                print(f\"{role.capitalize()}: {content}\")\n",
    "            except AttributeError:\n",
    "                # This will execute if .text does not exist\n",
    "                print(f\"{role.capitalize()}: [Non-text content, possibly an image or other file type]\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the file names from the response and retrieve the content\n",
    "asst_name = 'engineer'        \n",
    "files_from_messages(messages, asst_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('engineer_output_1.csv')\n",
    "display(df1)\n",
    "\n",
    "df2 = pd.read_csv('engineer_output_2.csv')\n",
    "display(df2)\n",
    "\n",
    "df3 = pd.read_csv('engineer_output_3.csv')\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315fb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.assistants.delete(my_assistant.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cdb7f7-a8f4-4ad9-bdba-900ab34c42d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load and check the file for the engineer\n",
    "asst_file = 'engineer_output_1.csv'\n",
    "df = pd.read_csv(asst_file)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1336118-fc38-4f8d-9115-1c294ad04a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the assistant and give it the CSV file\n",
    "\n",
    "mls = '''\n",
    "You are a data scientist who will build a predictive model with data from two csv files uploaded to your files. \n",
    "When the user asks you to perform your actions, use the csv file to read the data into a pandas dataframe.\n",
    "Then continue with each of the steps listed below in you ACTIONS. The user will identify the target variable. \n",
    "\n",
    "ACTIONS:\n",
    "\n",
    "1. Load the engineer_output_1 csv file into a pandas df of the same name.\n",
    "2. Split the data set into training and testing data sets with a 25% split.\n",
    "3. Train an Extra Trees random forest with 2000 trees\n",
    "4. Use the testing data to measure the models accuracy, presicion, recall, and confusion matrix.\n",
    "5. Format the testing data results as a csv table and prepare it for download by the user. \n",
    "\n",
    "DO NOT:\n",
    "1. Return any images. \n",
    "'''\n",
    "\n",
    "# send the csv file to the assistant purpose files\n",
    "response = client.files.create(\n",
    "  file=open(asst_file, \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "print(response)\n",
    "file_1_id = response.id\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=mls,\n",
    "    name=\"modeler_1\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4-1106-preview\", # gpt-4\n",
    "    file_ids=[file_1_id] # multiple files: file_ids=[file_1_id, file_2_id]\n",
    ")\n",
    "\n",
    "# get the file id\n",
    "fileId = my_assistant.file_ids[0]\n",
    "print(my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5cdf49-54c9-417e-a18d-43fd45c2b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the request to the assistant\n",
    "\n",
    "message_string = \"Please execute your ACTIONS on \" + fileId + \" and prepare the resulting table for csv download. The Target variable is Class\"\n",
    "print(message_string)\n",
    "\n",
    "# Step 2: Create a Thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Step 3: Add a Message to a Thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content= message_string\n",
    ")\n",
    "\n",
    "# Step 4: Run the Assistant\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=my_assistant.id\n",
    "    #instructions=\"Overwrite hard-coded instructions here\"\n",
    ")\n",
    "\n",
    "print(run.model_dump_json(indent=4))\n",
    "\n",
    "while True:\n",
    "    # Wait in between tries\n",
    "    sec = 60\n",
    "    time.sleep(sec)  \n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print('One eternity later...')\n",
    "    # If run is completed, get messages\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "        # Loop through messages and print content based on role\n",
    "        for msg in messages.data:\n",
    "            role = msg.role\n",
    "            try:\n",
    "                content = msg.content[0].text.value\n",
    "                print(f\"{role.capitalize()}: {content}\")\n",
    "            except AttributeError:\n",
    "                # This will execute if .text does not exist\n",
    "                print(f\"{role.capitalize()}: [Non-text content, possibly an image or other file type]\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b542310-582c-4f97-a69b-1b2323a784af",
   "metadata": {},
   "outputs": [],
   "source": [
    "asst_name = 'modeler'        \n",
    "files_from_messages(messages, asst_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18cde6-00c1-41d6-b346-d068438b05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('modeler_output_1.csv')\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113f438-97c8-4482-b00b-5ebce8b3882d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up the assistant\n",
    "\n",
    "response = client.beta.assistants.delete(my_assistant.id)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
