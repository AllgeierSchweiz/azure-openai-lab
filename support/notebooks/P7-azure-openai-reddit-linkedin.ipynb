{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc07dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import praw\n",
    "from datetime import datetime\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from io import StringIO\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b52b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required variables from .env file.\n",
    "load_dotenv(dotenv_path=Path(\"C:\\\\Python\\\\azure-openai-lab\\\\.venv\\\\.env\")) #Error sometimes due to \\ or \\\\. Try one or the other. \"C:\\\\Python\\\\azure-openai-lab\\\\.venv\\\\.env\"\n",
    "\n",
    "# Load Azure OpenAI Key and Endpoint. These values can be found within the Azure OpenAI Service resource in portal.azure.com under Keys and Endpoint\n",
    "azure_oai_key = os.environ['AZURE_OPENAI_KEY_P34']\n",
    "azure_oai_endpoint = os.environ['AZURE_OPENAI_ENDPOINT_P34']\n",
    "\n",
    "reddit_api_id = os.environ['REDDIT_API_ID']\n",
    "reddit_api_secret = os.environ['REDDIT_API_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0fd819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = azure_oai_endpoint, \n",
    "        api_key=azure_oai_key,  \n",
    "        api_version=\"2024-10-21\" #\"2024-02-01\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eee940ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Authenticate\n",
    "reddit = praw.Reddit(\n",
    "    client_id=reddit_api_id,\n",
    "    client_secret=reddit_api_secret,\n",
    "    user_agent=\"CommentRetriever/0.1 by u/No_Way629\"\n",
    ")\n",
    "\n",
    "# 2) Fetch the submission\n",
    "submission = reddit.submission(url=\"https://www.reddit.com/r/MicrosoftFabric/comments/1k0ty76/lakehouse_sql_endpoint/\")\n",
    "\n",
    "# 4) Start building the output string with the post metadata and body\n",
    "lines = []\n",
    "post_time = datetime.utcfromtimestamp(submission.created_utc).isoformat()\n",
    "lines.append(f\"Post: {submission.title} (u/{submission.author})\")\n",
    "lines.append(f\"Time: {post_time}\")\n",
    "lines.append(f\"URL:  {submission.url}\\n\")\n",
    "lines.append(submission.selftext or \"[no body text]\")\n",
    "lines.append(\"\\n---\\nComments:\")\n",
    "\n",
    "# 5) Load all comments\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "# 6) Flatten and append each comment to output\n",
    "for comment in submission.comments.list():\n",
    "    c_time = datetime.utcfromtimestamp(comment.created_utc).isoformat()\n",
    "    author = comment.author or \"[deleted]\"\n",
    "    body   = comment.body.replace('\\n', ' ')\n",
    "    lines.append(f\"[{c_time}] u/{author}: {body}\")\n",
    "\n",
    "output = \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00932d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced System prompt\n",
    "systemcontent = \\\n",
    "\"\"\"\n",
    "### INSTRUCTIONS\n",
    "Persona: Act as social media expert Dr. Rachna Jain who specializes in strategies for using psychological principles to enhance social media content.\n",
    "Action: Create a social media post telling a story in the active voice that provide practical business value by Focusing on a single and clear Goal. The structure should be authentic and in the third person. The Text should be clear and professional (no emojis)\n",
    "Target Audience: The recipients of the post are business leaders, managers and professionals who are curious about optimizing their data landscape.\n",
    "\n",
    "### EXAMPLE\n",
    "\n",
    "Hidden Costs in Microsoft Fabric\n",
    "\n",
    "Did you know that mismatched home and capacity regions in Microsoft Fabric can lead to unexpected data transfer costs and performance issues? If your tenant's home region differs from your capacity region, you might be facing:â€‹\n",
    "Microsoft Fabric Community\n",
    "\n",
    "1. Increased data transfer expenses: Data moving between regions can incur additional charges.\n",
    "\n",
    "2. Performance lags: Certain metadata and features like screenshots and data alerts still process in the home region, potentially causing delays.\n",
    "\n",
    "3. Compliance challenges: Data residency requirements might be compromised, leading to governance concerns.\n",
    "\n",
    "Solution:\n",
    "\n",
    "1. Review your tenant's home region: Ensure it aligns with your capacity region to avoid unnecessary costs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bca1898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Sensitivity Challenges in Lakehouse SQL Endpoint\n",
      "\n",
      "A company recently migrated over 100 SSRS reports to Power BI paginated reports and modernized their legacy ETL processes using Microsoft Fabric. However, they encountered unexpected errors when connecting paginated reports to their new silver lakehouse via the SQL endpoint. The issue: table names were case-sensitive, causing reports to fail because the SQL queries had inconsistent casing.\n",
      "\n",
      "Why did this happen?\n",
      "\n",
      "- Lakehouse SQL endpoints follow the Parquet specification, making table names case-sensitive.\n",
      "- Existing SQL queries in reports often had inconsistent casing, leading to \"table not found\" errors.\n",
      "\n",
      "Practical solutions:\n",
      "\n",
      "1. Create a Fabric Data Warehouse with case-insensitive collation and build views referencing the lakehouse tables. This allows paginated reports to query tables without casing issues.\n",
      "2. Temporarily adjust Spark session settings to enforce consistent casing when writing tables to the lakehouse, though this may require careful management to avoid other Spark-related issues.\n",
      "\n",
      "Long-term Outlook:\n",
      "\n",
      "Microsoft has acknowledged this challenge and plans to introduce configurable collation options for Lakehouse SQL endpoints in the future. Until then, using views in a case-insensitive warehouse is a practical workaround.\n",
      "\n",
      "Action Step:\n",
      "\n",
      "Review your data migration strategy carefully, ensuring consistent table naming conventions or implementing intermediate solutions like warehouse views to avoid disruptions in your reporting workflows.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zero-Shot learning. Model has a token limit of 4096.\n",
    "\n",
    "# Send request to Azure OpenAI model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.5-preview\",       # or whichever model you prefer\n",
    "    temperature=0.4,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": systemcontent\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Create a post:\\n\"\n",
    "                + \"---\\n\"\n",
    "                + output\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "print(result + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5108fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730a93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f8728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
