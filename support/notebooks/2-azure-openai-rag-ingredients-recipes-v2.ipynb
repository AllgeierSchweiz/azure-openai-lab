{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "#————————————————————\n",
    "\n",
    "# Name: Azure OpenAI RAG (V1)\n",
    "\n",
    "# Purpose: \n",
    "\n",
    "# Verify token count and estimate cost.\n",
    "\n",
    "# Company: Allgeier Schweiz AG\n",
    "# Author: Nicolas Rehder (nrehder@allgeier.ch)\n",
    "# Create for: SDSC 2024\n",
    "# Date Created: 10.01.2024\n",
    "# Last Updated: 10.01.2024\n",
    "# Python Version: 3.10.4\n",
    "\n",
    "# General Sources:\n",
    "# https://cscblog.ethz.ch/index.php/2024/02/06/az-open-ai-rag-chromadb-langchain/\n",
    "# https://github.com/Azure-Samples/openai/blob/main/Basic_Samples/Chat/chat_with_your_own_data.ipynb\n",
    "# https://thenewstack.io/tutorial-use-chroma-and-openai-to-build-a-custom-qa-bot/\n",
    "# https://www.pinecone.io/learn/chunking-strategies/\n",
    "# https://python.langchain.com/docs/modules/model_io/prompts/few_shot_examples/\n",
    "# https://github.com/langchain-ai/langchain/issues/14123\n",
    "# https://github.com/langchain-ai/langchain/issues/15878\n",
    "# https://www.kaggle.com/code/peremartramanonellas/ask-your-documents-with-langchain-vectordb-hf\n",
    "# https://stackoverflow.com/questions/77087460/langchain-azure-openai-api-returning-additional-information-than-the-asked-q\n",
    "\n",
    "# Azure Openai Usage:\n",
    "\n",
    "# Additionals:\n",
    "\n",
    "# Download Python packages (run the below command in terminal if packages have not yet been installed)\n",
    "# pip install -r C:\\Python\\openai-lab\\support\\requirements\\requirements.txt\n",
    "\n",
    "#————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from io import StringIO\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Azure OpenAI Key and Endpoint. These values can be found within the Azure OpenAI Service resource in portal.azure.com under Keys and Endpoint\n",
    "load_dotenv(dotenv_path=Path(\"C:\\Python\\openai-lab\\.venv\\.env\"))\n",
    "azure_oai_key = os.environ['AZURE_OPENAI_KEY']\n",
    "azure_oai_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = azure_oai_endpoint, \n",
    "        api_key=azure_oai_key,  \n",
    "        api_version=\"2024-02-01\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import recipes csv\n",
    "\n",
    "path_input = r\"C:\\Python\\openai-lab\\data\\recipes.csv\" #Change path if required\n",
    "df = pd.read_csv(path_input , sep=',', on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List column headers\n",
    "# list(df)\n",
    "\n",
    "# Remove columns\n",
    "\n",
    "df = df.drop(['id', 'contributor_id', 'submitted'], axis=1)\n",
    "\n",
    "# Remove double whitespaces from name\n",
    "\n",
    "df[\"name\"] = df[\"name\"].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Create subset of data\n",
    "\n",
    "df = df[df[\"n_ingredients\"] > 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column with relevant information for LLM packed into one string\n",
    "\n",
    "df[\"dense_feature\"] = df.name + \"; \" + df.tags.apply(lambda x: str(x).strip(\"[]\").replace(\"'\", \"\")) + \"; \" + df.nutrition.apply(lambda x: str(x).strip(\"[]\").replace(\"'\", \"\")) + \"; \" + df.ingredients.apply(lambda x: str(x).strip(\"[]\").replace(\"'\", \"\")) + \"; \" + df.steps\n",
    "df_text_input = pd.DataFrame(df[\"dense_feature\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe input compatible with langchain chroma\n",
    "\n",
    "df_loader = DataFrameLoader(df_text_input, page_content_column=\"dense_feature\")\n",
    "df_document = df_loader.load()\n",
    "#display(df_document[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and store the Word Embeddings for the Dataset using Azure Openai\n",
    "\n",
    "# def text_embedding(text):\n",
    "#     response = client.embeddings.create(model=\"text-embedding-ada-002\", input=[text])\n",
    "#     return response.data[0].embedding\n",
    "\n",
    "\n",
    "openai_ef = AzureOpenAIEmbeddings(\n",
    "                deployment = \"text-embedding-ada-002\",\n",
    "                openai_api_key = azure_oai_key,\n",
    "                azure_endpoint = azure_oai_endpoint,\n",
    "                openai_api_version = \"2024-02-01\",\n",
    "                #openai_api_type = \"azure\",\n",
    "                #chunk_size = 1\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk input\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\\n\",\n",
    "    chunk_size = 256,\n",
    "    chunk_overlap  = 20\n",
    ")\n",
    "df_document_split = text_splitter.split_documents(df_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ChromaDB Vector Database collection based on the Azure OpenAI embeddings model. Vector Database is created locally.\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "                documents = df_document_split,\n",
    "                embedding = openai_ef,\n",
    "                collection_name = \"recipes\",\n",
    "                persist_directory = \"C:\\Python\\openai-lab\\data\\chromadb\", #\"./chroma_db\",\n",
    "                collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from disk\n",
    "\n",
    "#vectordb = Chroma(persist_directory = \"C:\\Python\\chromadb\", openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beef and mushroom stew; weeknight, time-to-make, course, main-ingredient, cuisine, preparation, occasion, north-american, main-dish, beef, eggs-dairy, pork, vegetables, canadian, easy, potluck, dinner-party, stove-top, dietary, low-sodium, comfort-food, low-carb, mushrooms, low-in-something, meat, taste-mood, to-go, equipment, 4-hours-or-less; 623.9, 70.0, 14.0, 20.0, 67.0, 98.0, 4.0; unsalted butter, olive oil, bacon, onion, garlic, carrot, celery, worcestershire sauce, bay leaf, dried thyme, black pepper, salt, cayenne pepper, all-purpose flour, stewing beef, red wine, chicken stock, white pearl onions, button mushroom, sour cream, flat-leaf italian parsley; ['in a dutch oven over medium heat , melt butter and add oil', 'add bacon pieces to fat and cook , stirring often , until bacon starts to brown', 'add onion , garlic , carrots , celery , worcestershire , and herbs and spices', 'cook , stirring often , until onion is softened', 'pat beef cubes dry with a paper towel , if necessary , then dredge in flour until cubes are evenly coated', 'increase heat under dutch oven to medium-high and cook beef , adding a few pieces at a time to pan', 'let pieces brown before adding new ones', 'when all beef cubes have browned , add wine to pan and cook for 1 minute , stirring and scraping up any brown bits on bottom of pan', 'add chicken stock and bring to a boil', 'reduce heat to low , partially cover pot , and let simmer for one hour', 'stir in pearl onions', \"if you don't want to be bothered peeling the pearl onions , substitute 1-1 / 2 cups of cubed yellow onion\", 'continue to cook on low heat , partially covered , for another hour', 'remove pot lid and add mushrooms', 'simmer for 30 additional minutes', 'beef should be very tender', 'just before serving , remove pot from heat and stir in sour cream and parsley', 'return to heat to heat through', 'do not allow to boil', 'taste , add more salt and pepper if necessary , fish out bay leaf and discard , and serve', 'i serve it with rice but mashed potatoes or egg noodles also work well']\n"
     ]
    }
   ],
   "source": [
    "#Perform a Similarity Search to view Vector Database output based on input query.\n",
    "\n",
    "query = \"Beef, Butter, Mushrooms, Onions, Cream\"\n",
    "#vector = text_embedding(query)\n",
    "\n",
    "vectordb_output = vectordb.similarity_search(query)\n",
    "\n",
    "# print results\n",
    "print(vectordb_output[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize Azure Openai through Langchain (Default gpt-35-turbo and fine-tuned gpt-35-turbo-0613-ft)\n",
    "\n",
    "client = AzureChatOpenAI(\n",
    "                deployment_name = \"gpt-35-turbo\", #\"gpt-35-turbo-0613-ft\",\n",
    "                openai_api_key = azure_oai_key,\n",
    "                azure_endpoint = azure_oai_endpoint,\n",
    "                openai_api_version = \"2023-05-15\",\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Few-Shot prompt\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"butter, lemon, juice of, salt, white pepper, egg yolks\",\n",
    "        \"output\": \"\"\"{\"name\":\"easiest ever hollandaise sauce\",\"minutes\":25,\"tags\":\"['30-minutes-or-less', 'time-to-make', 'course', 'main-ingredient', 'preparation', 'very-low-carbs', 'sauces', 'condiments-etc', 'eggs-dairy', 'eggs', 'stove-top', 'dietary', 'low-carb', 'savory-sauces', 'low-in-something', 'equipment', 'number-of-servings']\",\"nutrition\":\"[1290.4, 213.0, 4.0, 53.0, 22.0, 417.0, 1.0]\",\"n_steps\":7,\"steps\":\"['cut the butter into several pieces and bring to room temperature', 'in the top of a double boiler , combine egg yolks , lemon juice , salt and pepper', 'add a piece of butter', 'cook , stirring steadily with a wooden spoon or wire whisk , over , but not touching , boiling water', 'when butter melts and sauce begins to thicken , add remaining butter , stirring constantly until melted', 'continue cooking as sauce thickens , about 2 more minutes', 'immediately remove from heat']\",\"description\":\"the secret to this easy hollandaise sauce is in separating the egg yolks. remove all the egg whites, as they can thin the sauce. also, it is best prepared in a double boiler to prevent overheating. serve over cooked asparagus, broccoli, or broiled tomatoes.\",\"ingredients\":\"['butter', 'lemon, juice of', 'salt', 'white pepper', 'egg yolks']\",\"n_ingredients\":5}\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"bacon, onion, celery, carrot, garlic, butter, olive oil, lean ground beef, ground pork, beef consomme, dry white wine, crushed tomatoes, salt, black pepper, rubbed sage, oregano, red pepper flakes, nutmeg, milk, penne pasta\",\n",
    "        \"output\": \"\"\"{\"name\":\"real italian bolognese sauce\",\"minutes\":160,\"tags\":\"['time-to-make', 'course', 'cuisine', 'preparation', 'sauces', 'condiments-etc', 'european', 'italian', 'dietary', '4-hours-or-less']\",\"nutrition\":\"[1260.7, 97.0, 11.0, 71.0, 103.0, 119.0, 38.0]\",\"n_steps\":16,\"steps\":\"['in a dutch oven or medium size pot , heat butter and olive oil over medium heat until butter begins to froth', 'add onion , celery , carrot , garlic , and bacon', 'cook until onions are translucent', 'remove bacon and remove fat', 'chop lean portions of bacon in small pieces and return to pot', 'add ground beef and ground pork , and cook until meat loses red , raw color', 'raise heat and add wine and consomme', 'cook sauce until wine and consomme are mostly evaporated', 'turn heat down to simmer and add oregano , salt , pepper , sage , red pepper flakes , and nutmeg', 'let cook for approximately 20 minutes', 'add crushed tomatoes and bring heat to a boil', 'once the mixture comes to a boil , return to simmer', 'let sauce simmer partially covered for about 2 to 4 hours , stirring occasionally to prevent sticking', 'about 5 to 10 minutes before serving , add milk', 'sauce can now be added to cooked penne pasta , spaghetti or many other pastas to your liking', 'remaining sauce may be frozen for up to two months for future use']\",\"description\":\"after traveling throughout italy, savoring the fine tastes of bolognese from the many different regions, i decided to formulate my own. try it, you'll love it.\",\"ingredients\":\"['bacon', 'onion', 'celery', 'carrot', 'garlic', 'butter', 'olive oil', 'lean ground beef', 'ground pork', 'beef consomme', 'dry white wine', 'crushed tomatoes', 'salt', 'black pepper', 'rubbed sage', 'oregano', 'red pepper flakes', 'nutmeg', 'milk', 'penne pasta']\",\"n_ingredients\":20}\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template used to format each individual example.\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring together the examples with the system and user (human) inputs.\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"Act as a head chef and create flavourful recipe from a list of ingredients. Use the following pieces of context and the examples to create the recipe:\n",
    "{context}\"\"\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain to call Azure openai for Q&A using ChromaDB vector database data to enrich the prompt (RAG).\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "       llm=client,\n",
    "       retriever = vectordb.as_retriever(),\n",
    "       chain_type=\"stuff\",\n",
    "       chain_type_kwargs={\"prompt\": final_prompt}\n",
    ")\n",
    "result = chain.invoke({\"query\": query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
