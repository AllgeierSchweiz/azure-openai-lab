{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————\n",
    "\n",
    "# Name: Azure OpenAI Assistant API, Data Pre-processing for RAG\n",
    "\n",
    "# Purpose:  This notebook will use the Azure OpenAI Assistant API to conduct data pre-processing steps on the recipes CSV using for RAG.\n",
    "\n",
    "# Company: Allgeier Schweiz AG\n",
    "# Author: Nicolas Rehder (nrehder@allgeier.ch), Alex Dean (adean@allgeier.ch)\n",
    "# Create for: SDSC 2024\n",
    "# Date Created: 22.01.2024\n",
    "# Last Updated: 19.05.2024\n",
    "# Python Version: 3.10.4\n",
    "\n",
    "#General Sources:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/assistants-quickstart?tabs=command-line&pivots=programming-language-studio\n",
    "\n",
    "#Azure Openai Usage:\n",
    "# https://stackoverflow.com/questions/77986927/in-azure-openai-assistants-when-i-upload-a-file-and-save-it-where-is-that-file-s\n",
    "# https://techcommunity.microsoft.com/t5/fasttrack-for-azure/strategies-for-optimizing-high-volume-token-usage-with-azure/ba-p/4007751#:~:text=Understanding%20tokens%20and%20limits%20in,generation%2C%20translation%2C%20or%20summarization.\n",
    "\n",
    "#Additionals:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n",
    "\n",
    "# If necessary, download Python packages (run the below command in terminal if packages have not yet been installed)\n",
    "# pip install -r C:\\Python\\sdsc\\requirements.txt\n",
    "\n",
    "#————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from io import StringIO\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required variables from env file.\n",
    "load_dotenv(dotenv_path=Path(\"C:\\\\Python\\\\azure-openai-lab\\\\.venv\\\\.env\")) #Error sometimes due to \\ or \\\\. Try one or the other. /workspaces/azure-openai-lab/.venv/.env\n",
    "\n",
    "# Load Azure OpenAI Key and Endpoint. These values can be found within the Azure OpenAI Service resource in portal.azure.com under Keys and Endpoint\n",
    "azure_oai_key = os.environ['AZURE_OPENAI_KEY']\n",
    "azure_oai_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key = azure_oai_key,  \n",
    "    api_version = \"2024-02-15-preview\",\n",
    "    azure_endpoint = azure_oai_endpoint\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='assistant-ZL9Wks4GaFf7Rt6qtsY1UtMx', bytes=2915453, created_at=1716299570, filename='recipes.csv', object='file', purpose='assistants', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# Upload file into Azure OpenAI Service [NOT USED IN WORKSHOP]\n",
    "# path_input = r\"C:\\Python\\azure-openai-lab\\data\\recipes.csv\" #Change path if required\n",
    "\n",
    "# # send the csv file to the assistant purpose files\n",
    "# response = client.files.create(\n",
    "#   file=open(path_input, \"rb\"),\n",
    "#   purpose=\"assistants\"\n",
    "# )\n",
    "# print(response)\n",
    "# file__id = response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant-yJjDRA4iOizy89uOxKD9jUGR\n",
      "assistant-ZL9Wks4GaFf7Rt6qtsY1UtMx\n"
     ]
    }
   ],
   "source": [
    "# Import existing uploaded file on Azure OpenAI Service\n",
    "for i in client.files.list():\n",
    "    if i.filename == \"recipes\":\n",
    "        file__id = i.id\n",
    "        print(i.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data transformation instructions\n",
    "instructions = '''\n",
    "You are a senior data analyst who will work with data in a csv file in your files. \n",
    "You have access to a sandbox environment for writing Python code.\n",
    "When the user asks you to perform your actions, use the csv file to read the data into a pandas dataframe.\n",
    "Execute each of the steps listed below in your ACTIONS section.\n",
    "\n",
    "\n",
    "ACTIONS:\n",
    "\n",
    "1. Read the file data into a pandas DataFrame. \n",
    "2. Drop columns \"id\", \"contributor_id\" and \"submitted\".\n",
    "3. Trim column \"name\" by removing irregular text spacing at the front or back of each value while keeping single spaces between words.\n",
    "4. Filter the data where column \"tags\" contains the word vegan.\n",
    "5. Create a new column named \"dense_feature\" combining the values of the columns \"name\", \"tags\", \"nutrition\", \"ingredients\" and \"steps\" separated by a semicolon.\n",
    "6. Prepare a final data set named \"recipes-preprocessed\" that only has 50 rows randomly sampled from the dataframe from step 5.\n",
    "7. Prepare recipes-preprocessed as csv files for download by the user. \n",
    "\n",
    "DO NOT:\n",
    "1. Do not return any images. \n",
    "2. Do not return any other file types.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Azure OpenAI Assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"data analyst assistant\",\n",
    "    instructions = instructions,\n",
    "    tools = [{\"type\": \"code_interpreter\"}],\n",
    "    model = \"gpt-4-1106-preview\", #\"gpt-4-0125-preview\", #You must replace this value with the deployment name for your model.\n",
    "    file_ids=[file__id]\n",
    ")\n",
    "\n",
    "# Get the file id\n",
    "fileId = assistant.file_ids[0]\n",
    "\n",
    "# Create a thread\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize thread and start data transformation using the Azure OpenAI Assistant Code Interpreter\n",
    "prompt = \"Please execute your ACTIONS on the data stored in the csv file \" + fileId\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = \"user\",\n",
    "    content = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Azure OpenAI Assistant\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  #instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The data has been successfully processed according to the instructions, and the preprocessed dataset has been saved as a CSV file. You can download the file using the link below:\n",
      "\n",
      "[Download recipes-preprocessed.csv](sandbox:/mnt/data/recipes-preprocessed.csv) \n",
      "\n",
      "Should you need further analysis or any adjustments, please let me know!\n",
      "Assistant: It looks like the CSV file uses tabs (`\\t`) as delimiters instead of commas. The error message indicates that the CSV reader expected 34 fields but saw 49 in line 3, which suggests that there may be lists or arrays of values within some columns. These lists might be enclosed within square brackets (`[]`) and include commas, which could lead the CSV parser to mistakenly interpret them as separate fields.\n",
      "\n",
      "To properly read this CSV file, I will specify the tab delimiter and account for potentially complex structures within the fields. Let's attempt to read the file again with these considerations in mind.\n",
      "Assistant: It seems like there was an error while trying to read the CSV file. This error often occurs when the number of fields in the file is inconsistent; for example, there might be varying numbers of columns across rows. This can happen if some fields contain unescaped newlines or delimiters.\n",
      "\n",
      "I will attempt to read the CSV file again, trying to diagnose the issue by looking at the beginning of the file. This will help to determine the correct delimiter and understand the structure of the data. Let's proceed with diagnosing the issue.\n",
      "User: Please execute your ACTIONS on the data stored in the csv file assistant-8Grfdxht32ydSXcQrV1LkDds\n"
     ]
    }
   ],
   "source": [
    "# Check status of Azure OpenAI Assistant run\n",
    "while True:\n",
    "    sec = 30\n",
    "    # Wait for 30 seconds\n",
    "    time.sleep(sec)  \n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    # If run is completed, get messages\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "        # Loop through messages and print content based on role\n",
    "        for msg in messages.data:\n",
    "            role = msg.role\n",
    "            try:\n",
    "                content = msg.content[0].text.value\n",
    "                print(f\"{role.capitalize()}: {content}\")\n",
    "            except AttributeError:\n",
    "                # This will execute if .text does not exist\n",
    "                print(f\"{role.capitalize()}: [Non-text content, possibly an image or other file type]\")\n",
    "        break\n",
    "    elif run.status == \"requires_action\":\n",
    "        # handle function calling and continue with the execution\n",
    "        pass\n",
    "    elif run.status == \"expired\" or run.status==\"failed\" or run.status==\"cancelled\":\n",
    "        # run failed, expired, or was cancelled\n",
    "        break    \n",
    "    elif run.last_error != \"None\":\n",
    "        # run failed, expired, or was cancelled\n",
    "        break     \n",
    "    else:\n",
    "        print(\"In progress...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read csv files from Azure OpenAI Service\n",
    "output_path = r\"C:\\\\Python\\\\azure-openai-lab\\\\data\\\\\" #r\"/workspaces/azure-openai-lab/data/\"\n",
    "\n",
    "def read_and_save_file(first_file_id, file_name):    \n",
    "    # its binary, so read it and then make it a file like object\n",
    "    file_data = client.files.content(first_file_id)\n",
    "    file_data_bytes = file_data.read()\n",
    "    file_like_object = io.BytesIO(file_data_bytes)\n",
    "    #now read as csv to create df\n",
    "    returned_data = pd.read_csv(file_like_object)\n",
    "    returned_data.to_csv(output_path + file_name, index=False)\n",
    "    return returned_data\n",
    "    # file = read_and_save_file(first_file_id, \"analyst_output.csv\")\n",
    "    \n",
    "def files_from_messages():\n",
    "    messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id\n",
    "        )\n",
    "    first_thread_message = messages.data[0]  # Accessing the first ThreadMessage\n",
    "    message_ids = first_thread_message.file_ids\n",
    "    # Loop through each file ID and save the file with a sequential name\n",
    "    for i, file_id in enumerate(message_ids):\n",
    "        file_name = f\"recipes-preprocessed.csv\"  # Generate a sequential file name\n",
    "        read_and_save_file(file_id, file_name)\n",
    "        print(f'saved {file_name}')  \n",
    "\n",
    "# Extract the file names from the response, retrieve the content and save the data as a csv file \n",
    "files_from_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileDeleted(id='assistant-8Grfdxht32ydSXcQrV1LkDds', deleted=True, object='file')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean up Azure OpenAI environment\n",
    "client.beta.assistants.delete(assistant.id)\n",
    "client.beta.threads.delete(thread.id)\n",
    "client.files.delete(messages.data[0].file_ids[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
