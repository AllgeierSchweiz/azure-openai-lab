{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————\n",
    "\n",
    "# Name: Azure OpenAI Vanilla\n",
    "\n",
    "# Purpose:\n",
    "\n",
    "# This notebook will create a GPT Assistant data engineer using the OpenAI API, give it a data set, ask it to process it using it's instructions, and then prepare the resulting dataframe for download. The idea here is to test if the assistant can successfully complete data prep and some data engineering, then reduce the feature set using a logistic regression with LASSO regularization, subsetting only non-zero LASSO coefficient features in the final dataset. \n",
    "\n",
    "# This notebook will create a GPT Assistant using OpenAI's API and provide it with the training dataframe returned by the data engineer Assistant and a set of instructions to creating an \"Extra Trees\" Random Forest. Basic outline of instructions for the modeler:\n",
    "\n",
    "# 1. Load the provided dataframe into a pandas df.\n",
    "# 2. Split the data set into training and testing using a 75:25 split.\n",
    "# 3. Train an Extra Trees random forest with 2000 trees.\n",
    "# 4. Use the testing data to measure the model's accuracy, presicion, recall, and generate a confusion matrix.\n",
    "# 5. Return the results in a single csv table. \n",
    "\n",
    "# Company: Allgeier Schweiz AG\n",
    "# Author: Nicolas Rehder (nrehder@allgeier.ch)\n",
    "# Create for: SDSC 2024\n",
    "# Date Created: 22.01.2024\n",
    "# Last Updated: 22.01.2024\n",
    "# Python Version: 3.10.4\n",
    "\n",
    "#General Sources:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints?source=recommendations\n",
    "\n",
    "#Openai Usage:\n",
    "#\n",
    "\n",
    "#Additionals:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n",
    "\n",
    "# Download Python packages (run the below command in terminal if packages have not yet been installed)\n",
    "# pip install -r C:\\Python\\sdsc\\requirements.txt\n",
    "\n",
    "#————————————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from io import StringIO\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Azure OpenAI Key and Endpoint. These values can be found within the Azure OpenAI Service resource in portal.azure.com under Keys and Endpoint\n",
    "load_dotenv(dotenv_path=Path(\"C:\\Python\\sdsc\\.venv\\.env\"))\n",
    "azure_oai_key = os.environ['AZURE_OPENAI_KEY']\n",
    "azure_oai_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_summarize = \"The process of making maple syrup begins by tapping a spout (sometimes called a spile) into the sugar maple tree. The spile is inserted into the tree about 2 inches deep and the sap is collected as it flows out. The sap is then taken to a sugar shack where it is boiled down to concentrate the sugars. As the sap boils, water in the sap is evaporated and the syrup becomes more and more thick. Once the syrup reaches the right sugar content, which is usually when the boiling point reaches 219 degrees Fahrenheit, it is bottled and enjoyed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Maple syrup is made by tapping a spout into a sugar maple tree, collecting the sap, boiling it down to concentrate the sugars, and then bottling it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "        azure_endpoint = azure_oai_endpoint, \n",
    "        api_key=azure_oai_key,  \n",
    "        api_version=\"2023-05-15\"\n",
    "        )\n",
    "\n",
    "# Send request to Azure OpenAI model\n",
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-35-turbo\",\n",
    "   temperature=0.7,\n",
    "   max_tokens=120,\n",
    "   messages=[\n",
    "       {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "       {\"role\": \"user\", \"content\": \"Summarize the following text in 20 words or less:\\n\" + txt_summarize}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(\"Summary: \" + response.choices[0].message.content + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.completions.create(\n",
    "    model=\"gpt-35-turbo-instruct\", # This must match the custom deployment name you chose for your model.\n",
    "    prompt=\"<prompt>\"\n",
    ")\n",
    "\n",
    "print(completion.choices[0].text)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure OpenAI?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_completion['choices'][0]['message']['content'])\n",
    "\n",
    "embedding = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\", # model = \"deployment_name\".\n",
    "    input=\"<input>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"A\", \"B\", \"C\"] #max array size=2048\n",
    "\n",
    "embedding = client.embeddings.create(\n",
    "    input=inputs,\n",
    "    model=\"text-embedding-ada-002\" # This must match the custom deployment name you chose for your model.\n",
    "    # engine=\"text-embedding-ada-002\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
